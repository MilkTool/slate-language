define: #Tokenizer &parents: {StreamProcessor} &slots:
{#separators -> ASCIIString Character Whitespace copy}.
"A stream that collects characters and emits words separated by
any of the given separators."
"FIXME: ASCIIString Character Whitespace is not ASCII specific.
Being a whitespace needs some abstraction over the actual encoding."
"TODO: Design extension: parametrize Tokenizer on something more high level that works at the level of overriding #skipSeparators."

s@(Tokenizer traits) newOn: target &separators: separators
[| result |
  result := resend.
  separators ifNotNil: [result separators := separators].
  result
].

s@(ReadStream traits) split
"Answer a Tokenizer over the input argument with the default separators."
[Tokenizer newOn: s].

s@(ReadStream traits) splitWith: separators
"Answer a Tokenizer over the input argument with the given separators."
[Tokenizer newOn: s &separators: separators].

s@(Tokenizer traits) skipSeparators
[
  [s source isAtEnd not /\ [s isSeparator: s source peek]]
    whileTrue: [s source next].
  s
].

s@(Tokenizer traits) isAtEnd
[
  [s skipSeparators] on: Stream Exhaustion do: [| :c | ^ True].
  s source isAtEnd
].

s@(Tokenizer traits) reset
[
  resend.
  s source reset.
  s
].

s@(Tokenizer traits) contents
[
  s reset.
  s upToEnd
].

s@(Tokenizer traits) isSeparator: char
[
  s separators includes: char
].

s@(Tokenizer traits) elementType
"Since a Tokenizer returns sub-Sequences of its source."
[s source collectionType].

s@(Tokenizer traits) collectionType
"Answer a generic Sequence, since our elements are themselves Sequences."
[Array].

s@(Tokenizer traits) next
[
  [| :result |
   [s skipSeparators.
    [result nextPut: s source next]
      until: [s source isAtEnd \/ [s isSeparator: s source peek]].
    ] breakOn: Stream Exhaustion.
  result position isZero ifTrue: [s exhausted]]
    writingAs: s elementType
].
